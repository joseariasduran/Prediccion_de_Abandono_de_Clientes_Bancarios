{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto: Predicción de Abandono de Clientes (Churn) - Beta Bank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción y Contexto del Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la industria bancaria, la retención de clientes es un factor crucial para la rentabilidad a largo plazo. Recientemente, los analistas de **Beta Bank** han detectado una tendencia preocupante: los clientes están cancelando sus cuentas y abandonando el banco poco a poco cada mes.\n",
    "\n",
    "Tras un análisis financiero, los banqueros han llegado a una conclusión determinante: **es mucho más rentable retener a los clientes actuales que invertir recursos en atraer nuevos clientes.**\n",
    "\n",
    "Para abordar este problema de manera proactiva, el banco ha recopilado un conjunto de datos históricos que refleja el comportamiento pasado de los clientes y la terminación de sus contratos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Objetivo del Proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo principal de este proyecto es **desarrollar un modelo de Machine Learning capaz de predecir si un cliente dejará el banco pronto** (*clasificación binaria*). Al identificar a los clientes con alta probabilidad de abandono (*churn*), el banco podrá tomar medidas preventivas, como ofrecer incentivos o promociones personalizadas, para intentar retenerlos.\n",
    "\n",
    "Criterios de éxito:\n",
    "\n",
    "- Se requiere construir un modelo que alcance un valor en la **métrica F1 de al menos 0.59** en el conjunto de prueba.\n",
    "\n",
    "- Adicionalmente, se evaluará la métrica **AUC-ROC** para compararla con el valor F1 y determinar la capacidad predictiva general del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Metodología"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para cumplir con los objetivos trazados, el proyecto se dividirá en las siguientes fases:\n",
    "\n",
    "**1- Preparación de los Datos:** Carga del dataset, limpieza, tratamiento de valores ausentes en variables clave (*como Tenure*) y codificación de variables categóricas.\n",
    "\n",
    "**2- Análisis Inicial y Modelo Base:** Evaluación del equilibrio de clases en la variable objetivo y entrenamiento de un modelo inicial sin ajustes para establecer un punto de referencia.\n",
    "\n",
    "**3- Mejora del Modelo (*Manejo del Desequilibrio*):** Aplicación de técnicas de corrección de desequilibrio de clases (como el ajuste de pesos y el sobremuestreo/upsampling) e iteración de hiperparámetros para encontrar el modelo con el mejor rendimiento en validación.\n",
    "\n",
    "**4- Prueba Final:** Evaluación del mejor modelo seleccionado en un conjunto de datos de prueba independiente para verificar que se cumpla el umbral del valor F1 $\\ge$ 0.59 y análisis de la métrica AUC-ROC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 1: Descarga y Preparación de los Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este primer paso nos encargaremos de cargar los datos, limpiarlos eliminando columnas que no sirven para predecir, tratar los valores nulos, transformar las variables de texto a números y finalmente, dividir y escalar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos librerias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la base de datos\n",
    "\n",
    "df = pd.read_csv('/datasets/Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Revisamos la informacion de la base de datos\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspeccionamos la estructura e informacion de la base de datos\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tienen 10,000 registros, se cuentan con 14 columnas, solo la columnaa Tenure cuenta con valores ausentes, son de tipo object, numerico y flotanes.\n",
    "\n",
    "**Objetivo:** Son 10,000 registros con tamaño ideal para predecir el abandono de clientes utilizando la columna Exited.\n",
    "\n",
    "**Problema principal:** Le faltan 909 datos en la columna Tenure (tiempo de permanencia). Tienes que rellenar estos vacíos antes de aplicar cualquier modelo predictivo.\n",
    "\n",
    "**Limpieza obligatoria:** Se deben borrar las columnas que no aportan valor predictivo (RowNumber, CustomerId, Surname), convertir las columnas de texto a formato numérico (Geography, Gender) y estandarizar las columnas con números grandes (Balance, EstimatedSalary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza Inicial\n",
    "# Las columnas RowNumber, CustomerId y Surname no determinan si un cliente abandona el banco.\n",
    "# Por lo tanto, las eliminamos para no confundir al modelo.\n",
    "df = df.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tratamos los valores ausentes\n",
    "# La columna 'Tenure' tiene valores nulos. Usamos la mediana para rellenarlos y no perder esos clientes.\n",
    "df['Tenure'] = df['Tenure'].fillna(df['Tenure'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificamos de variables categoricas\n",
    "# Convertimos 'Geography' (país) y 'Gender' (género) en variables numéricas (0 y 1).\n",
    "# Usamos drop_first=True para evitar la redundancia de datos (trampa de las variables ficticias).\n",
    "df = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividision de datos\n",
    "# Separamos las características (X) y el objetivo a predecir (y)\n",
    "X = df.drop('Exited', axis=1)\n",
    "y = df['Exited']\n",
    "\n",
    "# Dividimos los datos en 3 partes: Entrenamiento (60%), Validación (20%) y Prueba (20%).\n",
    "# Usamos stratify=y para que la proporción de \"Exited\" se mantenga igual en los 3 conjuntos.\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=12345, stratify=y)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=12345, stratify=y_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalamos caracteristicas\n",
    "# Estandarizamos las variables numéricas para que todas tengan un peso similar en el modelo.\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustamos el escalador SOLO con los datos de entrenamiento\n",
    "scaler.fit(X_train[numeric])\n",
    "\n",
    "# Convierte las vistas en copias independientes\n",
    "X_train = X_train.copy()\n",
    "X_valid = X_valid.copy() \n",
    "X_test = X_test.copy()\n",
    "\n",
    "# Transformamos los tres conjuntos\n",
    "X_train[numeric] = scaler.transform(X_train[numeric])\n",
    "X_valid[numeric] = scaler.transform(X_valid[numeric])\n",
    "X_test[numeric] = scaler.transform(X_test[numeric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión:** Hemos transformado nuestros datos crudos en información limpia y numérica que un modelo de Machine Learning puede procesar. Al dividir los datos en tres conjuntos (entrenamiento, validación y prueba) y aplicar el escalado, garantizamos que el modelo aprenderá de forma correcta y podremos evaluarlo sin trampas ni fugas de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 2: Examen del Equilibrio de Clases y Modelo Base (Desequilibrado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer optimizaciones avanzadas, debemos entender cómo se distribuye lo que queremos predecir (los que se van vs. los que se quedan) y cómo se comporta un modelo si ignoramos esta distribución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proporción de clases en el objetivo (y):\n",
      "0    0.7963\n",
      "1    0.2037\n",
      "Name: Exited, dtype: float64\n",
      "\n",
      "Método Desequilibrado - F1 (Validación): 0.6112\n",
      "Método Desequilibrado - AUC-ROC: 0.8696\n"
     ]
    }
   ],
   "source": [
    "# 1- Analisis del equilibrio de clases\n",
    "print(\"Proporción de clases en el objetivo (y):\")\n",
    "print(y.value_counts(normalize=True))\n",
    "# El resultado mostrará aprox. 80% (0: Se quedan) y 20% (1: Se van)\n",
    "\n",
    "#  2- Entrenamiento de modelo sin correcciones\n",
    "# Entrenamos un Random Forest probando diferentes hiperparámetros.\n",
    "best_rf_imbalanced = None\n",
    "best_f1_imbalanced = 0\n",
    "\n",
    "# Iteramos sobre la cantidad de árboles (estimadores) y la profundidad de cada árbol\n",
    "for est in range(10, 51, 10):\n",
    "    for depth in range(1, 15):\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_valid = model.predict(X_valid)\n",
    "        \n",
    "        # Evaluamos con la métrica F1\n",
    "        f1 = f1_score(y_valid, predictions_valid)\n",
    "        if f1 > best_f1_imbalanced:\n",
    "            best_f1_imbalanced = f1\n",
    "            best_rf_imbalanced = model\n",
    "\n",
    "# Calculamos AUC-ROC usando las probabilidades (predict_proba)\n",
    "prob_valid = best_rf_imbalanced.predict_proba(X_valid)[:, 1]\n",
    "auc_roc = roc_auc_score(y_valid, prob_valid)\n",
    "\n",
    "print(f\"\\nMétodo Desequilibrado - F1 (Validación): {best_f1_imbalanced:.4f}\")\n",
    "print(f\"Método Desequilibrado - AUC-ROC: {auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión:**\n",
    "Descubrimos que las clases están muy desequilibradas (80% vs 20%). Al entrenar el modelo en estas condiciones, el valor F1 en validación llega apenas a ~0.61. Aunque no es terrible, el modelo tiende a predecir \"0\" (que el cliente se queda) la mayoría de las veces por ser la clase dominante, siendo ineficiente para encontrar a los clientes que realmente se van."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 3: Mejora de la Calidad del Modelo (Corregir el Desequilibrio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para que el modelo preste más atención a la clase minoritaria (los que se van), utilizaremos dos técnicas distintas y buscaremos los mejores hiperparámetros para cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Técnica 1 (Pesos) - F1: 0.6499 | AUC-ROC: 0.8698\n",
      "Técnica 2 (Upsampling) - F1: 0.6538 | AUC-ROC: 0.8758\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Tecnica 1: Ajuste de pesos (CLASS WEIGHT)\n",
    "# ==========================================\n",
    "best_rf_balanced = None\n",
    "best_f1_balanced = 0\n",
    "\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 15):\n",
    "        # Añadimos class_weight='balanced' para penalizar más los errores en la clase \"1\"\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth, class_weight='balanced')\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions_valid = model.predict(X_valid)\n",
    "        f1 = f1_score(y_valid, predictions_valid)\n",
    "        \n",
    "        if f1 > best_f1_balanced:\n",
    "            best_f1_balanced = f1\n",
    "            best_rf_balanced = model\n",
    "\n",
    "prob_valid_bal = best_rf_balanced.predict_proba(X_valid)[:, 1]\n",
    "auc_roc_bal = roc_auc_score(y_valid, prob_valid_bal)\n",
    "\n",
    "print(f\"Técnica 1 (Pesos) - F1: {best_f1_balanced:.4f} | AUC-ROC: {auc_roc_bal:.4f}\")\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# Tecnica 2: Sobremuestreo (UPSAMPLING)\n",
    "# ==========================================\n",
    "# Función para multiplicar las filas de la clase minoritaria\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    # Multiplicamos la clase \"1\" por el factor 'repeat'\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    \n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "# Como la clase 0 es ~4 veces mayor que la 1, repetimos la clase 1 unas 4 veces\n",
    "X_upsampled, y_upsampled = upsample(X_train, y_train, 4)\n",
    "\n",
    "best_rf_up = None\n",
    "best_f1_up = 0\n",
    "\n",
    "for est in range(10, 101, 10):\n",
    "    for depth in range(1, 15):\n",
    "        # Entrenamos con el nuevo set de datos sobremuestreado\n",
    "        model = RandomForestClassifier(random_state=12345, n_estimators=est, max_depth=depth)\n",
    "        model.fit(X_upsampled, y_upsampled)\n",
    "        predictions_valid = model.predict(X_valid)\n",
    "        f1 = f1_score(y_valid, predictions_valid)\n",
    "        \n",
    "        if f1 > best_f1_up:\n",
    "            best_f1_up = f1\n",
    "            best_rf_up = model\n",
    "\n",
    "prob_valid_up = best_rf_up.predict_proba(X_valid)[:, 1]\n",
    "auc_roc_up = roc_auc_score(y_valid, prob_valid_up)\n",
    "\n",
    "print(f\"Técnica 2 (Upsampling) - F1: {best_f1_up:.4f} | AUC-ROC: {auc_roc_up:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión:**\n",
    "Al aplicar técnicas para corregir el desequilibrio, nuestro modelo mejoró sustancialmente. Ambas técnicas (*class_weight='balanced' y Upsampling*) lograron subir el F1 a aproximadamente 0.65 en el conjunto de validación, dándonos seguridad de que el modelo ahora sí identifica correctamente a los clientes propensos a irse. Seleccionaremos el modelo entrenado con Upsampling (*best_rf_up*) para nuestra prueba final por su robustez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paso 4: Prueba Final del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestro modelo definitivo y optimizado. Ahora lo pondremos a prueba frente al conjunto de datos de Prueba (Test), datos que el modelo jamás ha visto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESULTADOS DE LA PRUEBA FINAL ===\n",
      "Métrica F1 (Conjunto de Prueba): 0.5996\n",
      "Métrica AUC-ROC (Conjunto de Prueba): 0.8522\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion Final\n",
    "# Usamos el mejor modelo guardado (best_rf_up) para predecir sobre X_test\n",
    "predictions_test = best_rf_up.predict(X_test)\n",
    "\n",
    "# Obtenemos las probabilidades de que la clase sea \"1\" (se va) para el AUC-ROC\n",
    "prob_test = best_rf_up.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculamos las métricas definitivas\n",
    "test_f1 = f1_score(y_test, predictions_test)\n",
    "test_auc_roc = roc_auc_score(y_test, prob_test)\n",
    "\n",
    "print(\"=== RESULTADOS DE LA PRUEBA FINAL ===\")\n",
    "print(f\"Métrica F1 (Conjunto de Prueba): {test_f1:.4f}\")\n",
    "print(f\"Métrica AUC-ROC (Conjunto de Prueba): {test_auc_roc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusión:**\n",
    "El modelo logró una puntuación F1 aproximada de 0.60, superando con éxito el umbral exigido para aprobar el proyecto (0.59). Además, el valor de la métrica AUC-ROC es de ~0.85, lo que significa que la capacidad general del modelo para distinguir entre los clientes leales y los que abandonarán el banco es muy alta (mucho mejor que el 0.5 de un modelo aleatorio).\n",
    "\n",
    "Hemos cumplido los objetivos del negocio: crear una herramienta confiable y probada para identificar a los clientes en riesgo de fuga para que los banqueros actúen y los salven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclucion General Impacto para el Negocio:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo resultante proporciona a Beta Bank una herramienta predictiva robusta y confiable. Al poder identificar de manera anticipada a los clientes con alta probabilidad de abandonar la institución, **el banco ahora puede optimizar sus recursos financieros, dirigiendo campañas de retención**, ofertas personalizadas y un mejor servicio al cliente específicamente a este segmento en riesgo, logrando así el objetivo financiero principal: ahorrar dinero al retener a los clientes actuales en lugar de gastar en la adquisición de nuevos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
